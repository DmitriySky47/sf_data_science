{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sber_data = pd.read_csv('data/sber_data.csv')\n",
    "sber_data.head()\n",
    "#display(sber_data.info())\n",
    "display(sber_data.tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2.2 Сколько районов Москвы и Московской области представлено в данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sber_data['sub_area'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2.3 \n",
    "Чему равна максимальная цена квартир (price_doc)? Введите это число полностью, без округлений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sber_data['price_doc'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2.4 \n",
    "Проверим, влияет ли уровень экологической обстановки в районе на цену квартиры. Постройте коробчатую диаграмму цен на квартиры (price_doc) в зависимости от уровня экологической обстановки в районе (ecology). Какой уровень ценится на рынке меньше всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "boxplot = sns.boxplot(data=sber_data, x='price_doc', y='ecology')\n",
    "boxplot.set_title('Boxplot для зависимости цены квартиры от экологической обстановки', fontsize=16)\n",
    "boxplot.set_xlabel('Цена на квартиры')\n",
    "boxplot.set_ylabel('Уровень экологической обстановки')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2.5<br>Постройте диаграмму рассеяния, которая покажет, как цена на квартиру (price_doc) связана с расстоянием до центра Москвы (kremlin_km). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "scatterplot = sns.scatterplot(\n",
    "    data=sber_data,\n",
    "    y='price_doc',\n",
    "    x='kremlin_km',\n",
    "    #hue='species',\n",
    "    s=15,\n",
    "    sizes=(50, 300)\n",
    "\n",
    ")\n",
    "scatterplot.set_title('Взаимосвязь стоимости квартир и расстояния до центра', fontsize=16)\n",
    "scatterplot.set_xlabel('Цена квартир')\n",
    "scatterplot.set_ylabel('Расстояние до центра')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выявление процента пропусков по столбцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_null_percent = sber_data.isnull().mean() * 100\n",
    "cols_with_null = cols_null_percent[cols_null_percent>0].sort_values(ascending=False)\n",
    "display(cols_with_null)\n",
    "\n",
    "\n",
    "#визуализируем\n",
    "cols_with_null.plot(\n",
    "    kind='bar',\n",
    "    figsize=(10, 4),\n",
    "    title='Распределение пропусков в данных'\n",
    ");\n",
    "\n",
    "#через тепловую карту\n",
    "colors = ['blue', 'yellow'] \n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "cols = cols_with_null.index\n",
    "ax = sns.heatmap(\n",
    "    sber_data[cols].isnull(),\n",
    "    cmap=sns.color_palette(colors),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отбрасывание записей и признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем копию исходной таблицы\n",
    "drop_data = sber_data.copy()\n",
    "\n",
    "# задаем минимальный порог: вычисляем 70% от числа строк, т.е. если в столбе более 21329 (из 30471 значений) пропусков то удаляем\n",
    "# (удаление применим потом к строкам и столбам)\n",
    "thresh = drop_data.shape[0]*0.7\n",
    "display(thresh)\n",
    "display(drop_data.shape)\n",
    "\n",
    "#удаляем столбцы, в которых более 30% (100-70) пропусков\n",
    "drop_data = drop_data.dropna(thresh=thresh, axis=1)\n",
    "\n",
    "#удаляем записи (строка), в которых есть хотя бы 1 пропуск\n",
    "drop_data = drop_data.dropna(how='any', axis=0)\n",
    "\n",
    "#отображаем результирующую долю пропусков\n",
    "drop_data.isnull().mean()\n",
    "\n",
    "print(drop_data.shape) # таблица сократилась примерно на 9500 (30%) строк и на один признак (столбец)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols_with_null.index\n",
    "sber_data[cols].hist(figsize=(20, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение с помощью словаря values\n",
    "<br>Проверяем процент пропусков - должен быть ноль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем копию исходной таблицы\n",
    "fill_data = sber_data.copy()\n",
    "#создаем словарь имя столбца: число(признак) на который надо заменить пропуски\n",
    "values = {\n",
    "    'life_sq': fill_data['full_sq'],\n",
    "    'metro_min_walk': fill_data['metro_min_walk'].median(),\n",
    "    'metro_km_walk': fill_data['metro_km_walk'].median(),\n",
    "    'railroad_station_walk_km': fill_data['railroad_station_walk_km'].median(),\n",
    "    'railroad_station_walk_min': fill_data['railroad_station_walk_min'].median(),\n",
    "    'hospital_beds_raion': fill_data['hospital_beds_raion'].mode()[0],\n",
    "    'preschool_quota': fill_data['preschool_quota'].mode()[0],\n",
    "    'school_quota': fill_data['school_quota'].mode()[0],\n",
    "    'floor': fill_data['floor'].mode()[0]\n",
    "}\n",
    "#заполняем пропуски в соответствии с заявленным словарем\n",
    "fill_data = fill_data.fillna(values)\n",
    "#выводим результирующую долю пропусков\n",
    "fill_data.isnull().mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем изменения распределения для сравнения было-стало после заполнения словарем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols_with_null.index\n",
    "fill_data[cols].hist(figsize=(20, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление индикатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем копию исходной таблицы\n",
    "indicator_data = sber_data.copy()\n",
    "#в цикле пробегаемся по названиям столбцов с пропусками\n",
    "for col in cols_with_null.index:\n",
    "    #создаем новый признак-индикатор как col_was_null\n",
    "    indicator_data[col + '_was_null'] = indicator_data[col].isnull()\n",
    "#создаем словарь имя столбца: число(признак) на который надо заменить пропуски   \n",
    "values = {\n",
    "    'life_sq': indicator_data['full_sq'],\n",
    "    'metro_min_walk': indicator_data['metro_min_walk'].median(),\n",
    "    'metro_km_walk': indicator_data['metro_km_walk'].median(),\n",
    "    'railroad_station_walk_km': indicator_data['railroad_station_walk_km'].median(),\n",
    "    'railroad_station_walk_min': indicator_data['railroad_station_walk_min'].median(),\n",
    "    'hospital_beds_raion': indicator_data['hospital_beds_raion'].mode()[0],\n",
    "    'preschool_quota': indicator_data['preschool_quota'].mode()[0],\n",
    "    'school_quota': indicator_data['school_quota'].mode()[0],\n",
    "    'floor': indicator_data['floor'].mode()[0]\n",
    "}\n",
    "#заполняем пропуски в соответствии с заявленным словарем\n",
    "indicator_data = indicator_data.fillna(values)\n",
    "#выводим результирующую долю пропусков\n",
    "indicator_data.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "КОМБИНИРОВАНИЕ МЕТОДОВ\n",
    "<br>- удалить столбцы, в которых более 30 % пропусков;\n",
    "<br>- удалить записи, в которых более двух пропусков одновременно;\n",
    "<br>- заполнить оставшиеся ячейки константами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаём копию исходной таблицы\n",
    "combine_data = sber_data.copy()\n",
    "\n",
    "#отбрасываем столбцы с числом пропусков более 30% (100-70)\n",
    "n = combine_data.shape[0] #число строк в таблице\n",
    "thresh = n*0.7\n",
    "combine_data = combine_data.dropna(how='any', thresh=thresh, axis=1)\n",
    "\n",
    "#отбрасываем строки с числом пропусков более 2 в строке\n",
    "m = combine_data.shape[1] #число признаков после удаления столбцов\n",
    "combine_data = combine_data.dropna(how='any', thresh=m-2, axis=0)\n",
    "\n",
    "#создаём словарь 'имя_столбца': число (признак), на который надо заменить пропуски \n",
    "values = {\n",
    "    'life_sq': combine_data['full_sq'],\n",
    "    'metro_min_walk': combine_data['metro_min_walk'].median(),\n",
    "    'metro_km_walk': combine_data['metro_km_walk'].median(),\n",
    "    'railroad_station_walk_km': combine_data['railroad_station_walk_km'].median(),\n",
    "    'railroad_station_walk_min': combine_data['railroad_station_walk_min'].median(),\n",
    "    'preschool_quota': combine_data['preschool_quota'].mode()[0],\n",
    "    'school_quota': combine_data['school_quota'].mode()[0],\n",
    "    'floor': combine_data['floor'].mode()[0]\n",
    "}\n",
    "#заполняем оставшиеся записи константами в соответствии со словарем values\n",
    "combine_data = combine_data.fillna(values)\n",
    "#выводим результирующую долю пропусков\n",
    "display(combine_data.shape)\n",
    "display(combine_data.isnull().mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выявление выбросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет статистических показателей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sber_data['life_sq'].describe()\n",
    "#Выбиваются минимум и максимум. Минимум объясняется, что это студии, макс скорее опечатка, смотрим в интернете какие есть квартиры\n",
    "\n",
    "print(sber_data[sber_data['life_sq'] == 0].shape[0])\n",
    "# смотрим сколько может быть студий\n",
    "\n",
    "display(sber_data[sber_data['life_sq'] > 7000])\n",
    "# смотрим квартиры с большой площадью и видим что жилая больше общей - это ошибка!\n",
    "\n",
    "outliers = sber_data[sber_data['life_sq'] > sber_data['full_sq']]\n",
    "print(outliers.shape[0])\n",
    "#смотрим сколько квартир с площадью жилой больше чем суммарная\n",
    "cleaned = sber_data.drop(outliers.index, axis=0)\n",
    "print(f'Результирующее число записей: {cleaned.shape[0]}')\n",
    "# удаляем такие случаи с площадью\n",
    "\n",
    "display(sber_data['floor'].describe())\n",
    "# смотрим дискрайб по этажности домов, снова нестыковки\n",
    "\n",
    "display(sber_data[sber_data['floor']> 50])\n",
    "# смотрим сколько квартир в домах выше 50 этажей - всего одна, значит ошибка, т.к в этом районе нет таких домов в 77 этажей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МЕТОД МЕЖКВАРТИЛЬНОГО РАЗМАХА (МЕТОД ТЬЮКИ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Построим гистограмму и коробчатую диаграмму для признака полной площади (full_sq)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "histplot = sns.histplot(data=sber_data, x='full_sq', ax=axes[0]);\n",
    "histplot.set_title('Full Square Distribution');\n",
    "boxplot = sns.boxplot(data=sber_data, x='full_sq', ax=axes[1]);\n",
    "boxplot.set_title('Full Square Boxplot');\n",
    "#графики уехавшие т.к. справа есть невидимые на экране пеньки, на кробке этот выброс виден - крайняя правая точка в районе 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Квантили вычисляются с помощью метода quantile().\n",
    "#Потенциальные выбросы определяются при помощи фильтрации данных по условию выхода за пределы верхней или нижней границы.\n",
    "#Функция по отображению квартилей\n",
    "def outliers_iqr(data, feature):\n",
    "    x = data[feature]\n",
    "    quartile_1, quartile_3 = x.quantile(0.25), x.quantile(0.75),\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * 1.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    outliers = data[(x<lower_bound) | (x > upper_bound)]\n",
    "    cleaned = data[(x>lower_bound) & (x < upper_bound)]\n",
    "    return outliers, cleaned\n",
    "\n",
    "#Применим функцию и выявим число выбросов\n",
    "outliers, cleaned = outliers_iqr(sber_data, 'full_sq')\n",
    "print(f'Число выбросов по методу Тьюки: {outliers.shape[0]}')\n",
    "print(f'Результирующее число записей: {cleaned.shape[0]}')\n",
    "\n",
    "#Согласно классическому методу Тьюки, под выбросы у нас попали 963 записи в таблице.\n",
    "# Давайте построим гистограмму и коробчатую диаграмму на новых данных cleaned_sber_data:\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "histplot = sns.histplot(data=cleaned, x='full_sq', ax=axes[0]);\n",
    "histplot.set_title('Cleaned Full Square Distribution');\n",
    "boxplot = sns.boxplot(data=cleaned, x='full_sq', ax=axes[1]);\n",
    "boxplot.set_title('Cleaned Full Square Boxplot');\n",
    "# выбросы еще сохранились, надо отбрасывать еще возможно другими методами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАДАНИЕ 6.1 \n",
    "<br>Давайте немного модифицируем функцию outliers_iqr(). Добавьте в неё параметры left и right, которые задают число IQR влево и вправо от границ ящика (пусть по умолчанию они равны 1.5). Функция, как и раньше, должна возвращать потенциальные выбросы и очищенный DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_iqr_mod(data, feature, left=1.5, right=1.5):\n",
    "    x = data[feature]\n",
    "    quartile_1, quartile_3 = x.quantile(0.25), x.quantile(0.75),\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * left)\n",
    "    upper_bound = quartile_3 + (iqr * right)\n",
    "    outliers = data[(x<lower_bound) | (x> upper_bound)]\n",
    "    cleaned = data[(x>lower_bound) & (x < upper_bound)]\n",
    "    return outliers, cleaned\n",
    "\n",
    "outliers, cleaned = outliers_iqr_mod(sber_data, 'full_sq', left=1, right=6)\n",
    "print(f'Число выбросов по методу Тьюки: {outliers.shape[0]}')\n",
    "print(f'Результирующее число записей: {cleaned.shape[0]}')\n",
    "\n",
    "# После модификации выбросов становится меньше\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))\n",
    "histplot = sns.histplot(data=cleaned, x='full_sq', ax=axes[0]);\n",
    "histplot.set_title('Cleaned Full Square Distribution');\n",
    "boxplot = sns.boxplot(data=cleaned, x='full_sq', ax=axes[1]);\n",
    "boxplot.set_title('Cleaned Full Square Boxplot');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МЕТОД Z-ОТКЛОНЕНИЙ (МЕТОД СИГМ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим две гистограммы признака расстояния до МКАД (mkad_km): первая — в обычном масштабе, а вторая — в логарифмическом. Логарифмировать будем с помощью функции log() из библиотеки numpy (натуральный логарифм — логарифм по основанию числа e). Признак имеет среди своих значений 0. Из математики известно, что логарифма от 0 не существует, поэтому мы прибавляем к нашему признаку 1, чтобы не логарифмировать нули и не получать предупреждения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n",
    "\n",
    "#гистограмма исходного признака\n",
    "histplot = sns.histplot(sber_data['mkad_km'], bins=30, ax=axes[0])\n",
    "histplot.set_title('MKAD Km Distribution');\n",
    "\n",
    "#гистограмма в логарифмическом масштабе\n",
    "log_mkad_km= np.log(sber_data['mkad_km'] + 1)\n",
    "histplot = sns.histplot(log_mkad_km , bins=30, ax=axes[1])\n",
    "histplot.set_title('Log MKAD Km Distribution');\n",
    "\n",
    "'''\n",
    "Левое распределение напоминает логнормальное распределение с наличием потенциальных выбросов-«пеньков»,\n",
    "далеко отстоящих от основной массы наблюдений.\n",
    "Взяв натуральный логарифм от левого распределения, мы получаем правое, которое напоминает слегка перекошенное нормальное.\n",
    "Слева от моды (самого высокого столбика) наблюдается чуть больше наблюдений, нежели справа.\n",
    "По-научному это будет звучать так: «распределение имеет левостороннюю асимметрию».\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Примечание: Численный показатель асимметрии можно вычислить с помощью метода:\n",
    "#skew():\n",
    "print(log_mkad_km.skew())\n",
    "# -0.14263612203024953\n",
    "#Асимметрия распределения называется правосторонней, если она положительная:\n",
    "#Асимметрия распределения называется левосторонней, если она отрицательная:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию outliers_z_score(), которая реализует этот алгоритм. \n",
    "На вход она принимает DataFrame и признак, по которому ищутся выбросы. В дополнение добавим в функцию возможность работы в логарифмическом масштабе: для этого введём аргумент log_scale. Если он равен True, то будем логарифмировать рассматриваемый признак, иначе — оставляем его в исходном виде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_z_score(data, feature, log_scale=False):\n",
    "    if log_scale:\n",
    "        x = np.log(data[feature]+1)\n",
    "    else:\n",
    "        x = data[feature]\n",
    "    mu = x.mean()\n",
    "    sigma = x.std()\n",
    "    lower_bound = mu - 3 * sigma\n",
    "    upper_bound = mu + 3 * sigma\n",
    "    outliers = data[(x < lower_bound) | (x > upper_bound)]\n",
    "    cleaned = data[(x > lower_bound) & (x < upper_bound)]\n",
    "    return outliers, cleaned\n",
    "\n",
    "#Применим эту функцию к таблице sber_data и признаку mkad_km, а также выведем размерности результатов:\n",
    "outliers, cleaned = outliers_z_score(sber_data, 'mkad_km', log_scale=True)\n",
    "print(f'Число выбросов по методу z-отклонения: {outliers.shape[0]}')\n",
    "print(f'Результирующее число записей: {cleaned.shape[0]}')\n",
    "\n",
    "#Итак, метод z-отклонения нашел нам 33 потенциальных выброса по признаку расстояния до МКАД.\n",
    "# Давайте узнаем, в каких районах (sub_area) представлены эти квартиры:\n",
    "print(outliers['sub_area'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, мы не учли того факта, что наш логарифм распределения всё-таки не идеально нормален и в нём присутствует некоторая асимметрия. Возможно, стоит дать некоторое «послабление» на границы интервалов? Давайте отдельно построим гистограмму прологарифмированного распределения, а также отобразим на гистограмме вертикальные линии, соответствующие среднему (центру интервала в методе трёх сигм) и границы интервала . Вертикальные линии можно построить с помощью метода axvline(). Для среднего линия будет обычной, а для границ интервала — пунктирной (параметр ls ='--'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "log_mkad_km = np.log(sber_data['mkad_km'] + 1)\n",
    "histplot = sns.histplot(log_mkad_km, bins=30, ax=ax)\n",
    "histplot.axvline(log_mkad_km.mean(), color='k', lw=2)\n",
    "histplot.axvline(log_mkad_km.mean()+ 3 * log_mkad_km.std(), color='k', ls='--', lw=2)\n",
    "histplot.axvline(log_mkad_km.mean()- 3 * log_mkad_km.std(), color='k', ls='--', lw=2)\n",
    "histplot.set_title('Log MKAD Km Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАДАНИЕ 6.3<br>\n",
    "Давайте расширим правило трёх сигм, чтобы иметь возможность особенности данных. Добавьте в функцию outliers_z_score() параметры left и right, которые будут задавать число сигм (стандартных отклонений) влево и вправо соответственно, определяющее границы метода z-отклонения. По умолчанию оба параметры равны 3. Результирующую функцию назовите outliers_z_score_mod()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sb_data = sber_data.copy()\n",
    "\n",
    "def outliers_z_score_mod(data, feature, log_scale=False, left = 3, right = 3):\n",
    "    if log_scale:\n",
    "        x = np.log(data[feature]+1)\n",
    "    else:\n",
    "        x = data[feature]\n",
    "    mu = x.mean()\n",
    "    sigma = x.std()\n",
    "    lower_bound = mu - sigma * left\n",
    "    upper_bound = mu + sigma * right\n",
    "    outliers = data[(x < lower_bound) | (x > upper_bound)]\n",
    "    cleaned = data[(x > lower_bound) & (x < upper_bound)]\n",
    "    return outliers, cleaned\n",
    "    \"\"\"\n",
    "    Давайте расширим правило 3ех сигм, чтобы иметь возможность учитывать особенности данных.\n",
    "    Добавьте в функцию outliers_z_score() параметры left и right, которые будут задавать число сигм (стандартных отклонений) \n",
    "    влево и вправо соответственно, которые определяют границы метода z-отклонения. \n",
    "    По умолчанию оба параметры равны 3\n",
    "    \"\"\"\n",
    "    \n",
    "#outliers, cleaned = outliers_z_score_mod(sb_data, 'mkad_km', log_scale=True, left = 3, right=3.5)\n",
    "outliers, cleaned = outliers_z_score_mod(sb_data, 'price_doc', left=3.7, right=3.7, log_scale=True)\n",
    "#print(f'Число выбросов по методу z-отклонения: {outliers.shape[0]}')\n",
    "\n",
    "print(outliers.shape[0])\n",
    "#print(cleaned.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6.5<br>Постройте гистограмму для признака price_doc в логарифмическом масштабе. А также, добавьте на график линии, отображающие среднее и границы интервала для метода трех сигм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "log_price_doc = np.log(sber_data['price_doc'] + 1)\n",
    "histplot = sns.histplot(log_price_doc, bins=30, ax=ax)\n",
    "histplot.axvline(log_price_doc.mean(), color='k', lw=2)\n",
    "histplot.axvline(log_price_doc.mean()+ 3 * log_price_doc.std(), color='k', ls='--', lw=2)\n",
    "histplot.axvline(log_price_doc.mean()- 3 * log_price_doc.std(), color='k', ls='--', lw=2)\n",
    "histplot.set_title('Log MKAD Km Distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6.7<br>\n",
    "Добавьте фишку с логарифмированием в свою функцию outliers_iqr_mod(). Добавьте в неё параметр log_scale. Если он выставлен в True, то производится логарифмирование признака. Примените полученную функцию к признаку price_doc. Число межквартильных размахов в обе стороны обозначьте как 3. Чему равно число выбросов, полученных таким методом?\n",
    "\n",
    "При логарифмировании признака price_doc добавлять к нему 1 не нужно, он не имеет нулевых значений!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_iqr_mod(data, feature, left=1.5, right=1.5, log_scale=False):\n",
    "    if log_scale:\n",
    "        x = np.log(data[feature])\n",
    "    else:\n",
    "        x= data[feature]\n",
    "    quartile_1, quartile_3 = x.quantile(0.25), x.quantile(0.75),\n",
    "    iqr = quartile_3 - quartile_1\n",
    "    lower_bound = quartile_1 - (iqr * left)\n",
    "    upper_bound = quartile_3 + (iqr * right)\n",
    "    outliers = data[(x<lower_bound) | (x > upper_bound)]\n",
    "    cleaned = data[(x>lower_bound) & (x < upper_bound)]\n",
    "    return outliers, cleaned\n",
    "outliers, cleaned = outliers_iqr_mod(sber_data, 'price_doc', left=3, right=3, log_scale=True)\n",
    "print(f'Число выбросов по методу Тьюки: {outliers.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ДУБЛИКАТЫ<br>\n",
    "Онаружение и удаление дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим, есть у нас такие записи с дублями ID: для этого сравним число уникальных значений в столбце id с числом строк.\n",
    "# Число уникальных значений вычислим с помощью метода nunique():\n",
    "\n",
    "sber_data['id'].nunique() == sber_data.shape[0] # дублей ID нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ПОИСК ДУБЛИКАТОВ\n",
    "<br>Найдём число полных дубликатов таблице sber_data.\n",
    "<br>Предварительно создадим список столбцов dupl_columns, по которым будем искать совпадения (все столбцы, не включая id). \n",
    "<br>Создадим маску дубликатов с помощью метода duplicated() и произведём фильтрацию. Результат заносим в переменную sber_duplicates.\n",
    "<br>Выведем число строк в результирующем DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число найденных дубликатов: 562\n"
     ]
    }
   ],
   "source": [
    "dupl_columns = list(sber_data.columns)\n",
    "dupl_columns.remove('id')\n",
    "\n",
    "mask = sber_data.duplicated(subset=dupl_columns)\n",
    "sber_duplicates = sber_data[mask]\n",
    "print(f'Число найденных дубликатов: {sber_duplicates.shape[0]}') # найдено 562 полных дубликатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "УДАЛЕНИЕ ДУБЛИКАТОВ\n",
    "<br>Теперь нам необходимо от них избавиться. Для этого легче всего воспользоваться методом drop_duplicates(), который удаляет повторяющиеся записи из таблицы.\n",
    "<br>Создадим новую таблицу sber_dedupped, которая будет версией исходной таблицы, очищенной от полных дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результирующее число записей: 29909\n"
     ]
    }
   ],
   "source": [
    "sber_dedupped = sber_data.drop_duplicates(subset=dupl_columns)\n",
    "print(f'Результирующее число записей: {sber_dedupped.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обнаружение и удаление неинформативных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 100.0% уникальных значений\n",
      "oil_chemistry_raion: 99.03% одинаковых значений\n",
      "railroad_terminal_raion: 96.27% одинаковых значений\n",
      "nuclear_reactor_raion: 97.17% одинаковых значений\n",
      "big_road1_1line: 97.44% одинаковых значений\n",
      "mosque_count_1000: 98.08% одинаковых значений\n",
      "\n",
      "Результирующее число признаков: 55\n"
     ]
    }
   ],
   "source": [
    "#список неинформативных признаков\n",
    "low_information_cols = [] \n",
    "\n",
    "#цикл по всем столбцам\n",
    "for col in sber_data.columns:\n",
    "    #наибольшая относительная частота в признаке\n",
    "    top_freq = sber_data[col].value_counts(normalize=True).max()\n",
    "    #доля уникальных значений от размера признака\n",
    "    nunique_ratio = sber_data[col].nunique() / sber_data[col].count()\n",
    "    # сравниваем наибольшую частоту с порогом\n",
    "    if top_freq > 0.95:\n",
    "        low_information_cols.append(col)\n",
    "        print(f'{col}: {round(top_freq*100, 2)}% одинаковых значений')\n",
    "    # сравниваем долю уникальных значений с порогом\n",
    "    if nunique_ratio > 0.95:\n",
    "        low_information_cols.append(col)\n",
    "        print(f'{col}: {round(nunique_ratio*100, 2)}% уникальных значений')\n",
    "        \n",
    "        \n",
    "#Итак, мы нашли шесть неинформативных признаков.\n",
    "#Теперь можно удалить их с помощью метода drop(), передав результирующий список в его аргументы.\n",
    "\n",
    "information_sber_data = sber_data.drop(low_information_cols, axis=1)\n",
    "print()\n",
    "print(f'Результирующее число признаков: {information_sber_data.shape[1]}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af741f369a8dd187b80e5712a22afdb8733aeb51bfa419ddcaad81e3c7951da3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
