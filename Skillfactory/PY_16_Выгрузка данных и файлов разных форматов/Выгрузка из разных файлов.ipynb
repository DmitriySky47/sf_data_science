{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выгрузка данных из разных форматов файлов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с текстовыми файлами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция READ_TABLE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "countries_data = pd.read_csv('data/countries.csv', sep=';') # Загружаем данные из файла в переменную, создавая объект DataFrame\n",
    "countries_data.to_csv('data/countries.txt', index=False, sep=' ') # Выгружаем данные из DataFrame в CSV-файл и сохраняем файл в папке data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем данные из файла countries.txt в переменную txt_df  (объект DataFrame),\n",
    "<br>применив функцию read_table() с параметрами <b>sep=' '</b>  и  <b>index_col=['country']</b>\n",
    "<br>(так мы избавимся от столбца с индексом и присвоим названия строкам, используя данные одного из столбцов).\n",
    "<br>Выводим на экран полученный результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_df = pd.read_table('data/countries.txt', sep=' ', index_col=['country'])# Загружаем данные из файла в переменную, создавая объект DataFrame\n",
    "display(txt_df) # Выводим содержимое DataFrame на экран"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При считывании данных из ранее сохранённого в папке data файла melb_data_ps.csv указать значение параметра header=None, то первая строка исходного файла не будет восприниматься как строка заголовка и будет отнесена к области данных DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_data = pd.read_csv('data/countries.csv', sep=';', header=None) # Загружаем данные из файла в переменную, создавая объект DataFrame\n",
    "display(countries_data) # Выводим содержимое DataFrame на экран"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема с кодировкой исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data/ErrorEnCoding.csv', header=None ) # Считываем данные из файла с неизвестной кодировкой в переменную, создавая объект DataFrame\n",
    "display(data) # Выводим содержимое DataFrame на экран"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем кодировку файла\n",
    "\n",
    "\n",
    "from chardet.universaldetector import UniversalDetector # Импортируем субмодуль chardet.universaldetector\n",
    "detector = UniversalDetector()\n",
    "with open('data/ErrorEnCoding.csv', 'rb') as fh:\n",
    "    for line in fh:\n",
    "        detector.feed(line)\n",
    "        if detector.done:\n",
    "            break\n",
    "detector.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Создаем DataFrame из файла, явно указав кодировку символов, и выводим его содержимое на экран\n",
    "data=pd.read_csv('data/ErrorEnCoding.csv', encoding='koi8-r', header=None )\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение файла по ссылке URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_table('https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv', sep=',')\n",
    "display(data)\n",
    "display(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение и запись архивированных CSV-файлов\n",
    "<br> Важно!!! В архиве должен быть один файл. Если несколько, то работа с архивом будет отличаться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/students_performance.zip')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Архивируем CSV-файл\n",
    "\n",
    "compression_opts = dict(method='zip', archive_name='out.csv') # Определяем параметры архивирования — метод сжатия, имя файл в архиве\n",
    "data.to_csv('data/out.zip', index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение и запись в Excel: *read_excel()* и *to_excel()* из библиотеки *pandas*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "grades = pd.read_excel('data/grades.xlsx')\n",
    "display(grades)\n",
    "# display(grades.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение по ссылке URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>January 2020 Sales</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Sales Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Location</td>\n",
       "      <td>Oranges</td>\n",
       "      <td>Apples</td>\n",
       "      <td>Bananas</td>\n",
       "      <td>Blueberries</td>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toronto</td>\n",
       "      <td>7651</td>\n",
       "      <td>4422</td>\n",
       "      <td>8580</td>\n",
       "      <td>3679</td>\n",
       "      <td>24332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>273</td>\n",
       "      <td>2998</td>\n",
       "      <td>9890</td>\n",
       "      <td>7293</td>\n",
       "      <td>20454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>3758</td>\n",
       "      <td>6752</td>\n",
       "      <td>4599</td>\n",
       "      <td>4149</td>\n",
       "      <td>19258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York</td>\n",
       "      <td>4019</td>\n",
       "      <td>8796</td>\n",
       "      <td>8486</td>\n",
       "      <td>9188</td>\n",
       "      <td>30489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    January 2020 Sales Unnamed: 1 Unnamed: 2 Unnamed: 3   Unnamed: 4  \\\n",
       "0  Global Sales Report        NaN        NaN        NaN          NaN   \n",
       "1                  NaN        NaN        NaN        NaN          NaN   \n",
       "2             Location    Oranges     Apples    Bananas  Blueberries   \n",
       "3              Toronto       7651       4422       8580         3679   \n",
       "4          Los Angeles        273       2998       9890         7293   \n",
       "5              Atlanta       3758       6752       4599         4149   \n",
       "6             New York       4019       8796       8486         9188   \n",
       "\n",
       "  Unnamed: 5  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2      Total  \n",
       "3      24332  \n",
       "4      20454  \n",
       "5      19258  \n",
       "6      30489  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "#data = pd.read_excel('https://github.com/asaydn/test/raw/master/january.xlsx')\n",
    "data = pd.read_excel('data/january.xlsx')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные параметры метода read_excel()\n",
    "\n",
    "- io — первый параметр, в который мы передаём адрес файла, который хотим прочитать. Кроме адреса на диске, можно передавать адрес в интернете.\n",
    "- sheet_name —  ссылка на лист в Excel-файле (возможные значения данного параметра: 0 — значение по умолчанию, загружается первый лист; 'Sheet1' — можно передать название листа; обычно листы называются 'SheetX', где X — номер листа, но могут использоваться и другие названия; [0, 1, 'Sheet3'] — список, содержащий номера или названия листов; в таком случае Pandas вернёт словарь, в котором ключами будут номера или названия листов, а значениями — их содержимое в виде DataFrame; None — если передать такое значение, то pandas прочитает все листы и вернёт их в виде словаря, как в предыдущем пункте).\n",
    "- na_values — список значений, которые будут считаться пропусками ( ‘’, ‘#N/A’, ‘ N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’, ‘1.#IND’, ‘1.#QNAN’, ‘NA’, ‘NULL’, ‘NaN’, ‘n/a’, ‘nan’, ‘null’)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию в DataFrame читается информация из первого листа, однако read_excel()  позволяет выбрать, из какого именно листа загружать данные. Сделать это можно с помощью параметра sheet_name (рус. имя_листа). Например, чтобы прочесть данные из второго листа (ML) файла, выполним код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Student name</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Аня</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Катя</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Маша</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Миша</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Женя</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID Student name  Grade\n",
       "0           1          Аня      8\n",
       "1           2         Катя      9\n",
       "2           3         Маша      7\n",
       "3           4         Миша      4\n",
       "4           5         Женя      8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grades = pd.read_excel('data/grades.xlsx', sheet_name='Maths')\n",
    "display(grades.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3.3\n",
    "<br>Считайте данные из двух листов файла ratings+movies.xlsx в разные DataFrame, объедините в один, запишите данные из полученного DataFrame в файл. Сколько строк (включая строку заголовков) в результирующем файле?\n",
    "<br>Для выполнения следующего задания вам потребуется файл ratings+movies.xlsx, содержащий два листа с данными: ratings (таблица с информацией о выставленных оценках) и movies (таблица c расшифровками идентификаторов кинофильмов). Скачайте его и посмотрите, как он выглядит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_excel('data/ratings+movies.xlsx', sheet_name='ratings')\n",
    "movies_df = pd.read_excel('data/ratings+movies.xlsx', sheet_name='movies')\n",
    "\n",
    "display(ratings_df.info())\n",
    "display(movies_df.info())\n",
    "\n",
    "new_df = ratings_df.merge(\n",
    "movies_df,\n",
    "on='movieId',\n",
    "how='inner'\n",
    ")\n",
    "\n",
    "display(new_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополнительно для КПР\n",
    "#import pandas as pd\n",
    "#kvartal_df = pd.read_excel('KPR/kvartal_big.xlsx')\n",
    "#kvartal_df.info()\n",
    "\n",
    "#kvartal_df.to_excel('KPR/new_file_kvartal.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Открываем JSON\n",
    "<br>Чтобы перевести данные из формата JSON в формат, который можно обрабатывать инструментами Python, необходимо выполнить процедуру, которая называется десериализация (декодирование данных). Обратный процесс, связанный с переводом структур данных Python в формат JSON, называется сериализацией.\n",
    "<br>Для выполнения десериализации мы воспользуемся методом load() (от англ. загрузить) модуля json, который принимает на вход ссылку на открытый JSON-файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('data/recipes.json') as f: # Открываем файл и связываем его с объектом \"f\"\n",
    "    recipes = json.load(f) # Загружаем содержимое открытого файла в переменную recipes\n",
    "    \n",
    "'''Отлично! Теперь содержимое нашего файла загружено в переменную recipes.\n",
    "Давайте выведем его на экран с помощью функции pprint() из одноимённого модуля:'''\n",
    "pprint(recipes) # Выводим на экран содержимое переменной recipes, используя функция pprint()\n",
    "\n",
    "recipes[0]['id']\n",
    "recipes[0]['ingredients']\n",
    "len(recipes[0]['ingredients'])\n",
    "\n",
    "\n",
    "'''\n",
    "Задание 5.2   К какой кухне относится блюдо с id = 13121?\n",
    "'''\n",
    "\n",
    "for i in recipes: # начинаем перебор всех блюд входящих в список\n",
    "    if i['id'] == 13121: # если id текущего блюда равен заданному для поиска\n",
    "        print(i['cuisine']) # выводим на экран наименование кухни, к которой относится блюдо\n",
    "        break # прерываем выполнение цикла, т.к. нужное блюдо найдено"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 5.3\n",
    "<br>На практике также иногда возникают задачи по извлечению из JSON-файла обобщённой информации. Давайте попробуем решить две такие задачи.\n",
    "<br>Какое количество уникальных национальных кухонь присутствуют в нашем наборе данных?\n",
    "<br>\n",
    "- ВАРИАНТ РЕШЕНИЯ С ИСПОЛЬЗОВАНИЕМ СПИСКА\n",
    "<br>\n",
    "Чтобы извлечь эту информацию, нам нужно создать пустой список и последовательно заполнять его уникальными значениями, доступными по ключу 'cuisine' в каждом из словарей, содержащих информацию о рецептах. Поскольку словари объединены в список recipes, не получится применить известный нам метод unique() (этот метод неприменим к словарям), и для извлечения всех уникальных значений нужно перебирать элементы списка в цикле с параметром.\n",
    "<br><br>\n",
    "- ВАРИАНТ РЕШЕНИЯ С ИСПОЛЬЗОВАНИЕМ МНОЖЕСТВА\n",
    "<br>\n",
    "Другой способ решения этой же задачи — использование для хранения данных о разных кухнях не списка, а множества (set). Множество содержит только уникальные элементы, поэтому при работе с ним нет необходимости проверять, содержится ли там тот или иной элемент. Если элемент (в нашем примере — название типа кухни) уже есть, то команда \"добавить во множество такое же значение\" будет проигнорирована компьютером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('data/recipes.json') as f: # Открываем файл и связываем его с объектом \"f\"\n",
    "    recipes = json.load(f) # Загружаем содержимое открытого файла в переменную recipes\n",
    "    \n",
    "    \n",
    "    # если значения нет в списке то добавляем его как новое\n",
    "    uniq_1 = []\n",
    "    for i in recipes:\n",
    "        if not(i['cuisine'] in uniq_1):\n",
    "            uniq_1.append(i['cuisine'])\n",
    "    print('Первое решение', len(uniq_1))\n",
    "    \n",
    "    # добавляем все значения в set все повторяющиеся значения будут игнорироваться\n",
    "    uniq_set = set()\n",
    "    for i in recipes:\n",
    "        uniq_set.add(i['cuisine'])\n",
    "    print('Второе решение', len(uniq_set))\n",
    "    \n",
    "    # добавляем все значения в список потом преобразуем в set и оставим уникальные значения\n",
    "    uniq_list = list()\n",
    "    for i in recipes:\n",
    "        uniq_list.append(i['cuisine'])\n",
    "    uniq_list_set = set(uniq_list)\n",
    "    print('Третье решение', len(uniq_list_set))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 5.4\n",
    "<br>Какой из национальных кухонь принадлежит самое большое количество рецептов?\n",
    "<br>Возможный алгоритм действий:\n",
    "<br>Импортируем необходимые модули.\n",
    "<br>1. Загружаем содержимое открытого файла в переменную recipes.\n",
    "<br>2. Создаём список уникальных значений кухонь.\n",
    "<br>3. Создаём словарь для хранения информации о количестве рецептов в каждой кухне (ключ cuisine, значение — количество рецептов) и заполняем.\n",
    "<br>4. Определяем ключ с максимальным значением количества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('data/recipes.json') as f: # Открываем файл и связываем его с объектом \"f\"\n",
    "    recipes = json.load(f) # Загружаем содержимое открытого файла в переменную recipes\n",
    "    \n",
    "    cuisines = [] # создаем пустой список для ловли уникальных значений кухонь\n",
    "    for i in recipes:\n",
    "        if not(i['cuisine'] in cuisines): # проверяем есть ли значение в списке\n",
    "            cuisines.append(i['cuisine'])\n",
    "    \n",
    "# Пустой словарь для подсчета рецептов по каждой кухне\n",
    "cnt = {}\n",
    "\n",
    "# Перебор списка кухонь циклом\n",
    "for item in cuisines:\n",
    "    cnt[item] = 0 # Каждое значение в списке превращаем в ключ словаря и присваиваем значение ноль 0\n",
    "    \n",
    "for j in recipes: # Перебираем название кухонь циклом\n",
    "    cnt[j['cuisine']] += 1 # Увеличиваем значение по ключу-кухня на один как только она встречается в исходном файле\n",
    "    \n",
    "# Извлекаем значения для всех ключей используя метод get(), выбираем самое максимальное значение\n",
    "# (при наличии одинаковых значений будет выбрано первое в словаре) и выводим на экран ключ максимального значения\n",
    "print(max(cnt, key=cnt.get))\n",
    "\n",
    "print(cnt['italian'])\n",
    "\n",
    "# Преобразовали в таблицу\n",
    "# df = pd.DataFrame(cnt, index=[0])\n",
    "#display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas считываение JSON и формирование DATA FRAME\n",
    "<br>Pandas может считывать файл напрямую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('data/recipes.json') as f:\n",
    "    recipes = json.load(f)\n",
    "\n",
    "# Первый способ\n",
    "df = pd.DataFrame(recipes)\n",
    "display(df.head())\n",
    "\n",
    "#Второй способ (продвинутый) через метод read_json\n",
    "df_2 = pd.read_json('data/recipes.json') # Считываем файл через библиотеку Pandas напрямую - указывает path к файлу\n",
    "display(df_2.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Каждая строка соответствует одному рецепту, в столбце id хранится его идентификационный номер, в столбце cuisine — тип кухни, а столбец ingredients содержит список, в котором перечислены ингредиенты, необходимые для приготовления блюда.\n",
    "\n",
    "- Такая структура не очень практична, поскольку она не позволяет осуществлять группировку данных и выполнять многие другие операции, связанные с исследованием ингредиентов разных блюд. Например, представьте, что вы хотите отфильтровать блюда, состоящие не более чем из пяти ингредиентов, или блюда, не содержащие мяса. Сделать это, когда ингредиенты блюд хранятся в списках, не очень просто.\n",
    "\n",
    "- Для полноценной работы с данными нам необходимо иметь возможность хранить информацию о каждом ингредиенте в отдельном столбце\n",
    "\n",
    "- Работу над преобразованием DataFrame начнём с создания и заполнения столбцов, содержащих сведения о наличии или отсутствии каждого ингредиента в рецепте. Процесс заполнения выполним в два этапа:\n",
    "\n",
    "- 1 Создадим функцию для заполнения значения в каждой ячейке. Функция будет проверять наличие конкретного ингредиента в столбце ingredients для текущего блюда и возвращать 1, если ингредиент есть в рецепте, и 0, если он отсутствует.\n",
    "\n",
    "- 2 Организуем цикл, в котором будем перебирать наименования всех ингредиентов DataFrame (для этого потребуется создать реестр, то есть некий список, который содержит уникальные наименования ингредиентов). Для каждого ингредиента создадим в DataFrame столбец с соответствующим названием и заполним его единицами и нулями, применив к DataFrame, а точнее к столбцу ingredients функцию, созданную нами на предыдущем этапе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('data/recipes.json') as f:\n",
    "    recipes = json.load(f)\n",
    "    \n",
    "all_ingredients = set() # создали пустой set, чтобы записать значение всех уникальных ингридиентов\n",
    "for recipe in recipes: # перебираем циклом все рецепты\n",
    "    for ingredient in recipe['ingredients']: # вложенным циклом перебираем все ингридиенты в текущем рецепте\n",
    "        all_ingredients.add(ingredient) # в set будем добавлять все ингридиенты, т.к. set, то сохранятся только уникальные значения\n",
    "            \n",
    "#print(len(all_ingredients))\n",
    "\n",
    "df = pd.DataFrame(recipes) # Создаем объект DataFrame из списка recipes\n",
    "#display(df.head())\n",
    "\n",
    "#- Определим функцию contains(), с помощью которой мы будем проверять наличие\n",
    "#конкретного ингредиента ingredient_name в рецепте текущего блюда, который представлен\n",
    "#списком ingredient_list (значение в ячейке столбца ingredients текущего рецепта).\n",
    "#- Функция будет возвращать 1, если ингредиент есть в рецепте, и 0, если он отсутствует\n",
    "\n",
    "def contains(ingredient_list): # Определяем имя функции и передаваемые аргументы\n",
    "    if ingredient_name in ingredient_list: # Если ингредиент есть в текущем блюде,\n",
    "        return 1 # возвращаем значение 1\n",
    "    else: # Если ингредиента нет в текущем блюде,\n",
    "        return 0 # возвращаем значение 0\n",
    "    \n",
    "\n",
    "#Перебираем все ингредиенты из ранее созданного реестра all_ingredients с помощью цикла  for  и создать в DataFrame столбец\n",
    "#с соответствующим названием, заполнив его единицами и нулями. Для этого применим к DataFrame, а точнее, к столбцу ingredients функцию contains()\n",
    "\n",
    "for ingredient_name in all_ingredients: # Последовательно перебираем ингредиенты в реестре all_ingredients\n",
    "    df[ingredient_name] = df['ingredients'].apply(contains) # В DataFrame cоздаем столбец с именем текущего ингредиента и\n",
    "    #заполняем его единицами и нулями, используя ранее созданную функцию contains\n",
    "    \n",
    "df['ingredients'] = df['ingredients'].apply(len) # Заменяем список ингредиентов в рецепте, на их количество\n",
    "#display(df.info)\n",
    "\n",
    "df.to_csv('data/recipes.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратная сериализация DATA FRAME  в JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 7.1\n",
    "<br>Напишите код для создания списка id всех блюд, нужны только уникальные значения представленных в DataFrame.<br>Строки импорта библиотек в поле для ответа загружать не нужно. Результирующий список занесите в переменную ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # Импорт модуля json\n",
    "df = pd.read_csv('data/recipes.csv') # Создаём DataFrame, читаем данные из файла в переменную df\n",
    "\n",
    "ids = list(df['id'].unique()) # создаем список (list) уникальных id рецептов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 7.2\n",
    "<br>Напишите код для создания списка ингредиентов всех блюд, представленных в DataFrame.<br>Результирующий список занесите в переменную ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients = list(df.columns)[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 7.3\n",
    "<br>Напишите код функции make_list(), которая принимает на вход одну строку DataFrame, содержащую данные об одном рецепте, и возвращает перечень ингредиентов этого блюда в виде списка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list(row): # Определяем имя функции и передаваемые аргументы\n",
    "    ingredient_list=[] # Создаем пустой список ингредиентов текущего блюда\n",
    "    for i in ingredients: # Последовательно перебираем ингредиенты из реестра\n",
    "        if row[i].item()==1: # Если текущий ингредиент входит в состав текущего блюда\n",
    "            ingredient_list.append(i) # Добавляем ингредиент в список ингредиентов текущего блюда\n",
    "    return ingredient_list # Возвращаем сформированный список ингредиентов\n",
    "\n",
    "\n",
    "new_recipes = [] # Создаём пустой список для хранения итоговой структуры\n",
    "for current_id in ids: # Организуем цикл с параметром current_id\n",
    "    cuisine = df[df['id'] == current_id]['cuisine'].iloc[0] # Получаем значение соответствующей кухни,\n",
    "                                                             #применив фильтр по текущему значению параметра цикла к DataFrame;\n",
    "    current_ingredients = make_list(df[df['id'] == current_id]) # Получаем перечень ингредиентов, входящих в состав текущего блюда\n",
    "    current_recipe = {'cuisine': cuisine, 'id': int(current_id), 'ingredients': current_ingredients} # Создаём текущий словарь\n",
    "    new_recipes.append(current_recipe) # Добавляем созданный словарь к списку\n",
    "    \n",
    "    \n",
    "    \n",
    "new_recipes = json.dumps(new_recipes) # Функция dumps() модуля json сериализирует объект Python в строку формата JSON. \n",
    "with open(\"data/new_recipes.json\", \"w\") as write_file: # Откроем файл new_recipes.json для записи\n",
    "    write_file.write(new_recipes) # Записываем содержимое подготовленные данные в файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Открываем XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('data/menu.xml')\n",
    "root = tree.getroot()\n",
    "display(root) #Посмотрим на корневой узел - menu\n",
    "display(type(root)) # Посмотрим тип узла\n",
    "display(list(root)) #Возвращаем перечень потомков\n",
    "display(len(list(root))) # Можно посчитать кол-во потомков через len()\n",
    "display(list(root[1])) # Возвращаем перечень потомков от второго потомка dish. Индексация как и всегд а с нуля.\n",
    "display(root[0].attrib) #Вернет атрибут первого блюда из меню\n",
    "display(root[0][0]) # Возвражаем первый атрибут первого блюда, но пока не само значение атрибута\n",
    "display(root[0][0].text) # А теперь через TEXT вернули само значение первого атрибута первого блюда\n",
    "display(root.tag) # Вернем наименование тега конкретного узла через TAG\n",
    "display(root[0][2].tag) # Вернем наименование тега третьего (индексация с нуля!) узла из первого узла от корня\n",
    "\n",
    "\n",
    "# Обход всего дерева циклом  for\n",
    "for i in root:\n",
    "    for j in i:\n",
    "        print(i.attrib['name'], j.tag, j.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАГРУЖАЕМ ДАННЫЕ ИЗ XML-ФАЙЛА В DATAFRAME\n",
    "<br><br>\n",
    "Реализуем следующий алгоритм:\n",
    "<br>\n",
    "<br>1. Загрузить XML-структуру файла menu.xml в переменную root.\n",
    "<br>2. Создать пустой список df_list (в него будем добавлять строчки итоговой таблицы).\n",
    "<br>3. Заранее создать список column_names с именами столбцов — название блюда (name), его цена (price), вес (weight) и класс (class).\n",
    "<br>4. В цикле организовать обход xml-дерева из корня по всем потомкам.\n",
    "<br>5.На каждой итерации цикла сформировать в виде списка строку таблицы, содержащую информацию: наименование блюда (атрибут name узла dish) и значения потомков этого узла — узлов price, weight, class.\n",
    "<br>6.Добавить сформированную строку в список df_list, используя метод append().\n",
    "<br>7. Сформировать из вложенного списка DataFrame. Имена для столбцов взять из списка column_names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Кура', '40', '300', 'Мясо']]\n",
      "[['Кура', '40', '300', 'Мясо'], ['Греча', '20', '200', 'Крупа']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>weight</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Кура</td>\n",
       "      <td>40</td>\n",
       "      <td>300</td>\n",
       "      <td>Мясо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Греча</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>Крупа</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name price weight  class\n",
       "0   Кура    40    300   Мясо\n",
       "1  Греча    20    200  Крупа"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('data/menu.xml')\n",
    "root = tree.getroot() # Загружаем дерево\n",
    "\n",
    "column_names = ['name', 'price', 'weight', 'class'] # Список для наименование столбцов\n",
    "df_list = [] # Создали пустой список\n",
    "\n",
    "for dish in root: # Обходи всех потомков\n",
    "    row = [dish.attrib['name'], dish[0].text, dish[1].text, dish[2].text] # Описываем листья текущего потомка\n",
    "    df_list.append(row) # Сформированную выше строку добавляем в список, делаем многоуровневый большой список\n",
    "    print(df_list) # Показ многоуровнивости списка\n",
    "    \n",
    "df = pd.DataFrame(df_list, columns=column_names) # Формируем таблицу из многоуровневого списка, наименование столбцов из переменной column_names\n",
    "display(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание XML файла\n",
    "воссоздадим структуру с нуля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'price' at 0x0000027087EFC770>,\n",
       " <Element 'weight' at 0x0000027087EEF310>,\n",
       " <Element 'class' at 0x00000270869E5720>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<Element 'price' at 0x0000027087211E00>,\n",
       " <Element 'weight' at 0x00000270873A9F90>,\n",
       " <Element 'class' at 0x0000027087EF70E0>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Создаем корень дерева menu\n",
    "new_root = ET.Element('menu')\n",
    "\n",
    "# создаем первую и второю ветки dish1 и dish2 от корня\n",
    "dish1 = ET.SubElement(new_root, 'dish', name='Кура')\n",
    "dish2 = ET.SubElement(new_root, 'dish', name='Греча')\n",
    "\n",
    "# Создаем ветки-листья (price, weight, class) для веток\n",
    "price1 = ET.SubElement(dish1, 'price').text='40'\n",
    "weight1 = ET.SubElement(dish1, 'weight').text='300'\n",
    "class1 = ET.SubElement(dish1, 'class').text='Мясо'\n",
    "display(list(dish1))\n",
    "\n",
    "price2 = ET.SubElement(dish2, 'price').text='20'\n",
    "weight2 = ET.SubElement(dish2, 'weight').text='200'\n",
    "class2 = ET.SubElement(dish2, 'class').text='Крупа'\n",
    "display(list(dish2))\n",
    "\n",
    "\n",
    "#Сохраняем новый XML-файл\n",
    "\n",
    "ET.ElementTree(new_root).write('data/new_menu_good.xml', encoding=\"utf-8\") # Используем класс ElementTree, что бы решить вопрос кодировки\n",
    "\n",
    "# Альтернативное сохранение\n",
    "new_root_string = ET.tostring(new_root)\n",
    "with open('data/new_menu.xml', 'wb') as f:\n",
    "    f.write(new_root_string)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af741f369a8dd187b80e5712a22afdb8733aeb51bfa419ddcaad81e3c7951da3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
